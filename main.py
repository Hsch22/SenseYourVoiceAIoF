# -*- encoding: utf-8 -*-

import os
import sys
import argparse
import torch
import gradio as gr
import gradio.themes as grt
import time
import logging  # éœ€è¦å¯¼å…¥ logging ä»¥ä¾¿æ ¡éªŒå‡½æ•°ä½¿ç”¨

# å¯¼å…¥é…ç½®å’Œä¸»åº”ç”¨
from config import load_config
from app_new import SenseYourVoiceApp

# å…¨å±€åº”ç”¨å®ä¾‹
sense_app = None


logger = logging.getLogger('main_gradio_app')
if not logger.handlers:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    )

# è‡ªå®šä¹‰CSSæ ·å¼ - åŠ¨æ€æ¸å˜èƒŒæ™¯å’Œå¾®å…‰åŠ è½½æ•ˆæœ
CUSTOM_CSS = """
/* åŠ¨æ€æ¸å˜èƒŒæ™¯ */
.gradio-container {
    background: linear-gradient(-45deg, #ee7752, #e73c7e, #23a6d5, #23d5ab, #f093fb, #f5576c, #4facfe, #00f2fe);
    background-size: 400% 400%;
    animation: gradient-shift 15s ease infinite;
    min-height: 100vh;
}

@keyframes gradient-shift {
    0% { background-position: 0% 50%; }
    50% { background-position: 100% 50%; }
    100% { background-position: 0% 50%; }
}

/* å¾®å…‰åŠ è½½æ•ˆæœ */
.shimmer-loading {
    position: relative;
    overflow: hidden;
    background: linear-gradient(90deg, rgba(255,255,255,0.1) 25%, rgba(255,255,255,0.3) 50%, rgba(255,255,255,0.1) 75%);
    background-size: 200% 100%;
    animation: shimmer 2s infinite;
    border-radius: 8px;
    padding: 16px;
    margin: 16px 0;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255,255,255,0.2);
}

@keyframes shimmer {
    0% { background-position: -200% 0; }
    100% { background-position: 200% 0; }
}

/* å¾®å…‰åŠ è½½æŒ‡ç¤ºå™¨ */
.loading-indicator {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 8px;
    padding: 12px 24px;
    background: rgba(255,255,255,0.15);
    border-radius: 25px;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255,255,255,0.2);
    margin: 16px auto;
    width: fit-content;
}

.loading-dots {
    display: inline-flex;
    gap: 4px;
}

.loading-dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: linear-gradient(45deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
    animation: loading-pulse 1.4s infinite ease-in-out both;
}

.loading-dot:nth-child(1) { animation-delay: -0.32s; }
.loading-dot:nth-child(2) { animation-delay: -0.16s; }
.loading-dot:nth-child(3) { animation-delay: 0s; }

@keyframes loading-pulse {
    0%, 80%, 100% { transform: scale(0.8); opacity: 0.5; }
    40% { transform: scale(1.0); opacity: 1; }
}

/* å¢å¼ºæŒ‰é’®æ•ˆæœ */
.primary-button {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: none;
    border-radius: 8px;
    padding: 12px 24px;
    color: white;
    font-weight: 600;
    transition: all 0.3s ease;
    position: relative;
    overflow: hidden;
}

.primary-button:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
}

.primary-button::before {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
    transition: left 0.5s;
}

.primary-button:hover::before {
    left: 100%;
}

/* å¡ç‰‡å®¹å™¨ç¾åŒ– */
.card-container {
    background: rgba(255,255,255,0.1);
    backdrop-filter: blur(10px);
    border-radius: 16px;
    border: 1px solid rgba(255,255,255,0.2);
    padding: 20px;
    margin: 16px 0;
}

/* èŠå¤©æœºå™¨äººç¾åŒ– */
.chatbot-container {
    background: rgba(255,255,255,0.05);
    backdrop-filter: blur(10px);
    border-radius: 16px;
    border: 1px solid rgba(255,255,255,0.1);
}
"""


def validate_response_dict(
    response_dict, required_keys, context_msg="Stream"
):  # Modified context_msg default
    """
    æ ¡éªŒå‡½æ•°ï¼Œæ£€æŸ¥å­—å…¸ä¸­æ˜¯å¦å­˜åœ¨æ‰€æœ‰å¿…éœ€çš„é”®ã€‚
    å¦‚æœæ ¡éªŒå¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›ä¸€ä¸ªæ ‡å‡†çš„é”™è¯¯å­—å…¸ã€‚
    """
    if not isinstance(response_dict, dict):
        error_msg = f"{context_msg} - å“åº”ä¸æ˜¯ä¸€ä¸ªå­—å…¸: {type(response_dict)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg, "is_final": True}

    missing_keys = [key for key in required_keys if key not in response_dict]
    if missing_keys:
        error_msg = f"{context_msg} - å“åº”ä¸­ç¼ºå°‘å…³é”®å­—æ®µ: {', '.join(missing_keys)}"
        logger.error(error_msg)
        return {"success": False, "error": error_msg, "is_final": True}

    if (
        "success" in response_dict
        and not response_dict["success"]
        and "error" not in response_dict
    ):
        logger.warning(
            f"{context_msg} - å“åº”æ ‡è®°ä¸ºå¤±è´¥ä½†æœªæä¾›é”™è¯¯ä¿¡æ¯ã€‚åŸå§‹å“åº”: {response_dict}"
        )
    return None  # è¡¨ç¤ºæ ¡éªŒé€šè¿‡


def initialize_app(
    model_dir,
    device,
    understanding_api_key,
    understanding_api_url,
    specialized_api_key,
    specialized_api_url,
):
    """åˆå§‹åŒ–åº”ç”¨å®ä¾‹"""
    global sense_app

    # ä»ç”¨æˆ·è¾“å…¥åˆ›å»ºé…ç½®å­—å…¸
    user_config = {
        "model_dir": model_dir,
        "device": device,
        "understanding_api_key": understanding_api_key,
        "understanding_api_url": understanding_api_url,
        "specialized_api_key": specialized_api_key,
        "specialized_api_url": specialized_api_url,
    }

    # ä½¿ç”¨load_configå‡½æ•°åŠ è½½é…ç½®ï¼Œåˆå¹¶ç”¨æˆ·é…ç½®å’Œé»˜è®¤é…ç½®
    config = load_config(user_config)

    try:
        sense_app = SenseYourVoiceApp(config)
        return "åº”ç”¨åˆå§‹åŒ–æˆåŠŸï¼", gr.update(visible=False)  # éšè—åŠ è½½æŒ‡ç¤ºå™¨
    except Exception as e:
        return f"åº”ç”¨åˆå§‹åŒ–å¤±è´¥: {str(e)}", gr.update(visible=False)  # éšè—åŠ è½½æŒ‡ç¤ºå™¨


def process_audio(audio_file, chat_history, audio_text):
    """å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶å¹¶é€æ­¥æ›´æ–°å¯¹è¯å†å²"""
    global sense_app

    if sense_app is None:
        yield chat_history, None, "åº”ç”¨å°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆåˆå§‹åŒ–åº”ç”¨ã€‚", audio_text
        return

    if audio_file is None:
        yield chat_history, None, "è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ã€‚", audio_text
        return

    try:
        # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
        context = ""
        if chat_history:
            for user_msg, bot_msg in chat_history:
                if user_msg and bot_msg:
                    context += f"ç”¨æˆ·: {user_msg}\nåŠ©æ‰‹: {bot_msg}\n"

        # å¤„ç†éŸ³é¢‘æ–‡ä»¶
        result = sense_app.process(audio_file, context=context)  # Removed instruction

        if not result["success"]:
            yield chat_history, None, result["error"], audio_text
            return

        # è·å–éŸ³é¢‘è½¬å½•å†…å®¹
        transcription = result["transcription"]
        audio_text = transcription  # å­˜å‚¨éŸ³é¢‘æ–‡æœ¬å†…å®¹

        # ç³»ç»Ÿåé¦ˆæ¶ˆæ¯
        system_message = "å¤ªå¥½äº†ï¼æˆ‘å·²ç»æˆåŠŸç†è§£äº†æ‚¨çš„éŸ³é¢‘å†…å®¹ï½ ğŸ‰ æœ‰ä»€ä¹ˆæƒ³è¦äº†è§£æˆ–åˆ†æçš„å—ï¼Ÿæˆ‘å¾ˆä¹æ„ä¸ºæ‚¨è§£ç­”ï¼"
        new_chat_history = list(chat_history) if chat_history else []
        new_chat_history.append(("", system_message))

        for i in range(len(system_message) + 1):
            time.sleep(0.05)
            new_chat_history[-1] = ("", system_message[:i])
            yield new_chat_history, None, None, audio_text

        # ç¡®ä¿å®Œæ•´è¾“å‡º
        yield new_chat_history, None, None, audio_text
    except Exception as e:
        yield chat_history, None, f"å¤„ç†è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}", audio_text


def process_text(
    text_input, chat_history, audio_text, max_tokens, temperature, top_p, top_k
):
    """å¤„ç†ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬å¹¶é€æ­¥æ›´æ–°å¯¹è¯å†å²"""
    global sense_app

    if sense_app is None:
        yield chat_history, None, "åº”ç”¨å°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆåˆå§‹åŒ–åº”ç”¨ã€‚", audio_text
        return

    if not text_input or text_input.strip() == "":
        yield chat_history, None, "è¯·è¾“å…¥æ–‡æœ¬å†…å®¹ã€‚", audio_text
        return

    try:
        # æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬éŸ³é¢‘å†…å®¹
        context = ""
        if audio_text:
            context += f"éŸ³é¢‘å†…å®¹: {audio_text}\n"
        if chat_history:
            for user_msg, bot_msg in chat_history:
                if user_msg and bot_msg:
                    context += f"ç”¨æˆ·: {user_msg}\nåŠ©æ‰‹: {bot_msg}\n"

        # åˆ†æç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ (æµå¼)
        llm_params = {
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "top_k": top_k,
            # "stop": stop # Stop might be handled differently
        }

        new_chat_history = list(chat_history) if chat_history else []
        new_chat_history.append((text_input, ""))
        full_response = ""
        needs_specialized_task = False
        specialized_result_output = None  # ç”¨äºå­˜å‚¨ä¸“ä¸šä»»åŠ¡çš„æœ€ç»ˆç»“æœæˆ–æµå¼å—

        # å¤„ç†ç†è§£æ¨¡å—çš„æµå¼è¾“å‡º
        understanding_stream = sense_app.understanding.analyze(
            text_input, context=context, llm_params=llm_params
        )
        # --- å®šä¹‰ç†è§£æ¨¡å—æµå¼è¾“å‡ºæœŸæœ›çš„å…³é”®å­—æ®µ ---
        understanding_chunk_required_keys = ["success", "is_final"]

        for chunk_data in understanding_stream:
            # --- æ ¡éªŒ UnderstandingModule æµå¼å— ---
            validation_error = validate_response_dict(
                chunk_data,
                understanding_chunk_required_keys,
                "UnderstandingModule.analyze stream (main.py)",
            )
            if validation_error:
                # å¦‚æœæ ¡éªŒå¤±è´¥ï¼Œä¹Ÿéœ€è¦æ›´æ–°èŠå¤©è®°å½•ï¼ˆæ˜¾ç¤ºä¹‹å‰çš„å®Œæ•´å“åº”æˆ–éƒ¨åˆ†å“åº”ï¼‰
                # åŒæ—¶æ˜¾ç¤ºæ ¡éªŒé”™è¯¯
                yield new_chat_history, specialized_result_output, validation_error[
                    "error"
                ], audio_text
                return  # ç»“æŸç”Ÿæˆå™¨
            # --- æ ¡éªŒç»“æŸ ---

            if not chunk_data["success"]:
                # å¦‚æœåŸå§‹å“åº”å°±æ˜¯ error, ä¸”é€šè¿‡äº†æ ¡éªŒ (æ„å‘³ç€ success å’Œ is_final å­—æ®µå­˜åœ¨)
                yield new_chat_history, specialized_result_output, chunk_data.get(
                    "error", "ç†è§£æ¨¡å—å¤„ç†å‡ºé”™ä½†æœªè¿”å›å…·ä½“é”™è¯¯ä¿¡æ¯"
                ), audio_text
                return

            if chunk_data["is_final"]:
                needs_specialized_task = chunk_data.get("needs_specialized_task", False)
                full_response = chunk_data.get(
                    "full_response", full_response
                )  # è·å–å®Œæ•´å“åº”
                break  # ç†è§£æµç»“æŸ

            response_chunk = chunk_data.get("response_chunk", "")
            if response_chunk:
                full_response += response_chunk
                new_chat_history[-1] = (text_input, full_response)
                yield new_chat_history, specialized_result_output, None, audio_text

        # å¦‚æœéœ€è¦ä¸“ä¸šä»»åŠ¡å¤„ç† (æµå¼)
        if needs_specialized_task:
            task_type = sense_app._determine_task_type(
                full_response
            )  # ä½¿ç”¨å®Œæ•´å“åº”åˆ¤æ–­ä»»åŠ¡ç±»å‹
            specialized_task_stream = sense_app.specialized_task.process_task(
                task_type, full_response
            )

            full_specialized_result = ""  # ç”¨äºç´¯ç§¯ä¸“ä¸šä»»åŠ¡çš„æµå¼ç»“æœ
            specialized_result_output = ""  # åˆå§‹åŒ–ä¸“ä¸šä»»åŠ¡è¾“å‡ºä¸ºç©ºå­—ç¬¦ä¸²
            # --- å®šä¹‰ä¸“ä¸šä»»åŠ¡æ¨¡å—æµå¼è¾“å‡ºæœŸæœ›çš„å…³é”®å­—æ®µ ---
            specialized_chunk_required_keys = ["success", "is_final"]

            for specialized_chunk_data in specialized_task_stream:
                # --- æ ¡éªŒ SpecializedTaskModule æµå¼å— ---
                validation_error = validate_response_dict(
                    specialized_chunk_data,
                    specialized_chunk_required_keys,
                    "SpecializedTaskModule.process_task stream (main.py)",
                )
                if validation_error:
                    # ä¸“ä¸šä»»åŠ¡æ ¡éªŒå‡ºé”™ï¼ŒèŠå¤©è®°å½•ï¼ˆæ˜¾ç¤ºç†è§£ç»“æœï¼‰ä¸å˜ï¼Œä½†ä¸“ä¸šä»»åŠ¡ç»“æœåŒºæ˜¾ç¤ºé”™è¯¯
                    yield new_chat_history, specialized_result_output, validation_error[
                        "error"
                    ], audio_text
                    return  # ç»“æŸç”Ÿæˆå™¨
                # --- æ ¡éªŒç»“æŸ ---

                if not specialized_chunk_data["success"]:
                    # ä¸“ä¸šä»»åŠ¡å‡ºé”™ï¼Œä¹Ÿéœ€è¦æ›´æ–°èŠå¤©è®°å½•ï¼ˆæ˜¾ç¤ºä¹‹å‰çš„ç†è§£ç»“æœï¼‰
                    yield new_chat_history, specialized_result_output, specialized_chunk_data.get(
                        "error", "ä¸“ä¸šä»»åŠ¡æ¨¡å—å¤„ç†å‡ºé”™ä½†æœªè¿”å›å…·ä½“é”™è¯¯ä¿¡æ¯"
                    ), audio_text
                    return

                if specialized_chunk_data["is_final"]:
                    break  # ä¸“ä¸šä»»åŠ¡æµç»“æŸ

                result_chunk = specialized_chunk_data.get("result_chunk", "")
                if result_chunk:
                    full_specialized_result += result_chunk
                    specialized_result_output = full_specialized_result  # æ›´æ–°è¾“å‡º
                    # åœ¨ä¸“ä¸šä»»åŠ¡æµå¼è¾“å‡ºæ—¶ï¼ŒèŠå¤©è®°å½•é€šå¸¸ä¿æŒä¸å˜ï¼ˆæ˜¾ç¤ºç†è§£ç»“æœï¼‰
                    # ä½†ä¸“ä¸šä»»åŠ¡ç»“æœåŒºåŸŸä¼šæ›´æ–°
                    yield new_chat_history, specialized_result_output, None, audio_text

            # ä¸“ä¸šä»»åŠ¡æµç»“æŸåï¼Œç¡®ä¿æœ€ç»ˆçš„ä¸“ä¸šç»“æœè¢«ä¼ é€’
            specialized_result_output = full_specialized_result

        # ç¡®ä¿æœ€ç»ˆçŠ¶æ€è¢«ä¼ é€’
        yield new_chat_history, specialized_result_output, None, audio_text

    except Exception as e:
        yield chat_history, None, f"å¤„ç†è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}", audio_text


def main():
    # åŠ è½½é»˜è®¤é…ç½®
    default_config = load_config()

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="SenseYourVoice - Gradio WebUI")
    parser.add_argument(
        "--model_dir",
        type=str,
        default=default_config["model_dir"],
        help="è¯­éŸ³æ¨¡å‹ç›®å½•",
    )
    parser.add_argument(
        "--device", type=str, default=default_config["device"], help="è®¾å¤‡"
    )
    parser.add_argument(
        "--understanding_api_key",
        type=str,
        default=default_config["understanding_api_key"],
        help="ç†è§£æ¨¡å—APIå¯†é’¥",
    )
    parser.add_argument(
        "--understanding_api_url",
        type=str,
        default=default_config["understanding_api_url"],
        help="ç†è§£æ¨¡å—APIåœ°å€",
    )
    parser.add_argument(
        "--specialized_api_key",
        type=str,
        default=default_config["specialized_api_key"],
        help="ä¸“ä¸šä»»åŠ¡æ¨¡å—APIå¯†é’¥",
    )
    parser.add_argument(
        "--specialized_api_url",
        type=str,
        default=default_config["specialized_api_url"],
        help="ä¸“ä¸šä»»åŠ¡æ¨¡å—APIåœ°å€",
    )
    parser.add_argument(
        "--auto_init",
        action="store_true",
        default=default_config["auto_init"],
        help="è‡ªåŠ¨åˆå§‹åŒ–åº”ç”¨",
    )
    parser.add_argument(
        "--share",
        action="store_true",
        default=default_config["share"],
        help="åˆ›å»ºå…¬å…±é“¾æ¥åˆ†äº«ç•Œé¢",
    )
    parser.add_argument(
        "--port", type=int, default=default_config["port"], help="æœåŠ¡ç«¯å£"
    )
    args = parser.parse_args()

    # åˆ›å»ºGradioç•Œé¢
    with gr.Blocks(
        title="SenseYourVoice - è¯­éŸ³ç†è§£ä¸å¤„ç†", theme=grt.Citrus(), css=CUSTOM_CSS
    ) as demo:
        gr.Markdown(
            """
        # SenseYourVoice - è¯­éŸ³ç†è§£ä¸å¤„ç†
        ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è§£è¯»å¹¶è®°ä½å†…å®¹ï¼Œç„¶åæ‚¨å¯ä»¥è¿›è¡Œå¤šæ¬¡é—®ç­”äº’åŠ¨ã€‚
        """
        )

        # å¾®å…‰åŠ è½½æŒ‡ç¤ºå™¨
        loading_indicator = gr.HTML(
            """
            <div class="loading-indicator" style="display: none;">
                <span style="color: white; font-weight: 500;">å¤„ç†ä¸­</span>
                <div class="loading-dots">
                    <div class="loading-dot"></div>
                    <div class="loading-dot"></div>
                    <div class="loading-dot"></div>
                </div>
            </div>
            """,
            visible=False,
        )

        # åº”ç”¨è®¾ç½®éƒ¨åˆ†
        # with gr.Tab("åº”ç”¨è®¾ç½®"):
        #     model_dir = gr.Textbox(label="è¯­éŸ³æ¨¡å‹ç›®å½•", value=args.model_dir)
        #     device = gr.Dropdown(label="è®¾å¤‡", choices=["cuda:0", "cpu"], value=args.device)
        #     understanding_api_key = gr.Textbox(label="ç†è§£æ¨¡å—APIå¯†é’¥", value=args.understanding_api_key or "")
        #     understanding_api_url = gr.Textbox(label="ç†è§£æ¨¡å—APIåœ°å€", value=args.understanding_api_url or "")
        #     specialized_api_key = gr.Textbox(label="ä¸“ä¸šä»»åŠ¡æ¨¡å—APIå¯†é’¥", value=args.specialized_api_key or "")
        #     specialized_api_url = gr.Textbox(label="ä¸“ä¸šä»»åŠ¡æ¨¡å—APIåœ°å€", value=args.specialized_api_url or "")

        #     init_btn = gr.Button("åˆå§‹åŒ–åº”ç”¨")
        #     init_output = gr.Textbox(label="åˆå§‹åŒ–çŠ¶æ€")

        #     init_btn.click(
        #         fn=initialize_app,
        #         inputs=[model_dir, device, understanding_api_key, understanding_api_url, specialized_api_key, specialized_api_url],
        #         outputs=init_output
        #     )

        with gr.Tab("åº”ç”¨è®¾ç½®"):
            with gr.Row():
                with gr.Column(scale=1):  # å·¦ä¾§æ”¾æ¨¡å‹å’Œè®¾å¤‡
                    model_dir = gr.Textbox(label="è¯­éŸ³æ¨¡å‹ç›®å½•", value=args.model_dir)
                    device = gr.Dropdown(
                        label="è®¾å¤‡", choices=["cuda:0", "cpu"], value=args.device
                    )
                with gr.Column(scale=2):  # å³ä¾§æ”¾APIè®¾ç½®ï¼Œå¹¶åˆ†ç»„
                    with gr.Group():
                        gr.Markdown("### ç†è§£æ¨¡å— API")  # æ·»åŠ å°æ ‡é¢˜
                        understanding_api_key = gr.Textbox(
                            label="APIå¯†é’¥",
                            value=args.understanding_api_key or "",
                            type="password",
                        )  # ä½¿ç”¨å¯†ç ç±»å‹
                        understanding_api_url = gr.Textbox(
                            label="APIåœ°å€", value=args.understanding_api_url or ""
                        )
                    with gr.Group():
                        gr.Markdown("### ä¸“ä¸šä»»åŠ¡æ¨¡å— API")  # æ·»åŠ å°æ ‡é¢˜
                        specialized_api_key = gr.Textbox(
                            label="APIå¯†é’¥",
                            value=args.specialized_api_key or "",
                            type="password",
                        )  # ä½¿ç”¨å¯†ç ç±»å‹
                        specialized_api_url = gr.Textbox(
                            label="APIåœ°å€", value=args.specialized_api_url or ""
                        )

            init_btn = gr.Button("åˆå§‹åŒ–åº”ç”¨", elem_classes="primary_button")
            init_output = gr.Textbox(
                label="åˆå§‹åŒ–çŠ¶æ€", interactive=False
            )  # è®¾ç½®ä¸ºä¸å¯ç¼–è¾‘

            # ... click äº‹ä»¶ä¸å˜ ...
            init_btn.click(
                fn=initialize_app,
                inputs=[
                    model_dir,
                    device,
                    understanding_api_key,
                    understanding_api_url,
                    specialized_api_key,
                    specialized_api_url,
                ],
                outputs=[init_output, loading_indicator],
            )

        # è¯­éŸ³å¤„ç†éƒ¨åˆ†
        with gr.Tab("è¯­éŸ³å¤„ç†"):
            # æ·»åŠ Stateç»„ä»¶å­˜å‚¨å¯¹è¯å†å²å’ŒéŸ³é¢‘æ–‡æœ¬
            chat_history = gr.State([])
            audio_text = gr.State("")

            with gr.Row():
                with gr.Column():
                    gr.Markdown("### éŸ³é¢‘è¾“å…¥")
                    audio_input = gr.Audio(label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", type="filepath")
                    process_audio_btn = gr.Button("å¤„ç†éŸ³é¢‘")

                with gr.Column():
                    gr.Markdown("### æé—®ä¸å‚æ•°è®¾ç½®")
                    text_input = gr.Textbox(
                        label="è¾“å…¥é—®é¢˜", placeholder="è¯·æ ¹æ®éŸ³é¢‘å†…å®¹æé—®"
                    )
                    with gr.Accordion("å‚æ•°è®¾ç½®", open=False):
                        max_tokens = gr.Slider(
                            minimum=1,
                            maximum=4096,
                            value=default_config["llm_max_tokens"],
                            step=1,
                            label="Max Tokens",
                        )
                        temperature = gr.Slider(
                            minimum=0.0,
                            maximum=2.0,
                            value=default_config["llm_temperature"],
                            step=0.1,
                            label="Temperature",
                        )
                        top_p = gr.Slider(
                            minimum=0.0,
                            maximum=1.0,
                            value=default_config["llm_top_p"],
                            step=0.1,
                            label="Top P",
                        )
                        top_k = gr.Slider(
                            minimum=1,
                            maximum=100,
                            value=default_config["llm_top_k"],
                            step=1,
                            label="Top K",
                        )
                    process_text_btn = gr.Button("ç»§ç»­å¯¹è¯")

            # æ˜¾ç¤ºå¯¹è¯å†å²
            chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=400)

            clear_btn = gr.Button("æ¸…é™¤å¯¹è¯å†å²")

            specialized_output = gr.Markdown(label="ä¸“ä¸šä»»åŠ¡å¤„ç†ç»“æœ", visible=False)
            # specialized_output = gr.Textbox(label="ä¸“ä¸šä»»åŠ¡å¤„ç†ç»“æœ", visible=False)
            error_output = gr.Textbox(label="é”™è¯¯ä¿¡æ¯", visible=False)

            def process_and_update(audio_file, history, audio_text):
                """å¤„ç†éŸ³é¢‘å¹¶é€æ­¥æ›´æ–°ç•Œé¢"""
                # æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨
                yield history, history, gr.update(value="", visible=False), gr.update(
                    value="", visible=False
                ), audio_text, gr.update(visible=True)

                for new_history, specialized, error, new_audio_text in process_audio(
                    audio_file, history, audio_text
                ):
                    if error:
                        yield history, history, gr.update(
                            value="", visible=False
                        ), gr.update(value=error, visible=True), audio_text, gr.update(
                            visible=False
                        )
                    else:
                        yield new_history, new_history, gr.update(
                            value=specialized if specialized else "",
                            visible=specialized is not None,
                        ), gr.update(
                            value="", visible=False
                        ), new_audio_text, gr.update(
                            visible=False
                        )

            def process_text_and_update(
                text, history, audio_text, max_tokens, temperature, top_p, top_k
            ):
                """å¤„ç†æ–‡æœ¬å¹¶é€æ­¥æ›´æ–°ç•Œé¢"""
                # æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨
                yield history, history, gr.update(value="", visible=False), gr.update(
                    value="", visible=False
                ), audio_text, gr.update(value=text), gr.update(visible=True)

                for new_history, specialized, error, new_audio_text in process_text(
                    text, history, audio_text, max_tokens, temperature, top_p, top_k
                ):
                    if error:
                        yield history, history, gr.update(
                            value="", visible=False
                        ), gr.update(value=error, visible=True), audio_text, gr.update(
                            value=text
                        ), gr.update(
                            visible=False
                        )
                    else:
                        yield new_history, new_history, gr.update(
                            value=specialized if specialized else "",
                            visible=specialized is not None,
                        ), gr.update(
                            value="", visible=False
                        ), new_audio_text, gr.update(
                            value=text
                        ), gr.update(
                            visible=False
                        )

                yield new_history, new_history, gr.update(
                    value=specialized if specialized else "",
                    visible=specialized is not None,
                ), gr.update(value="", visible=False), new_audio_text, gr.update(
                    value=""
                ), gr.update(
                    visible=False
                )

            def clear_chat_history():
                """æ¸…é™¤å¯¹è¯å†å²å’ŒéŸ³é¢‘æ–‡æœ¬"""
                return (
                    [],
                    [],
                    gr.update(value="", visible=False),
                    gr.update(value="", visible=False),
                    "",
                )

            # å¤„ç†éŸ³é¢‘æŒ‰é’®äº‹ä»¶
            process_audio_btn.click(
                fn=process_and_update,
                inputs=[audio_input, chat_history, audio_text],
                outputs=[
                    chat_history,
                    chatbot,
                    specialized_output,
                    error_output,
                    audio_text,
                    loading_indicator,
                ],
            )

            # å¤„ç†æ–‡æœ¬æŒ‰é’®äº‹ä»¶
            process_text_btn.click(
                fn=process_text_and_update,
                inputs=[
                    text_input,
                    chat_history,
                    audio_text,
                    max_tokens,
                    temperature,
                    top_p,
                    top_k,
                ],
                outputs=[
                    chat_history,
                    chatbot,
                    specialized_output,
                    error_output,
                    audio_text,
                    text_input,
                    loading_indicator,
                ],
            )

            clear_btn.click(
                fn=clear_chat_history,
                inputs=[],
                outputs=[
                    chat_history,
                    chatbot,
                    specialized_output,
                    error_output,
                    audio_text,
                ],
            )

        gr.Markdown(
            """
        ### ä½¿ç”¨è¯´æ˜
        1. åœ¨"åº”ç”¨è®¾ç½®"æ ‡ç­¾é¡µä¸­é…ç½®å‚æ•°å¹¶åˆå§‹åŒ–åº”ç”¨ã€‚
        2. åœ¨"è¯­éŸ³å¤„ç†"æ ‡ç­¾é¡µä¸­ï¼š
           - **ä¸Šä¼ éŸ³é¢‘**ï¼šä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œç‚¹å‡»"å¤„ç†éŸ³é¢‘"ï¼Œç³»ç»Ÿä¼šè§£è¯»å¹¶åé¦ˆã€‚
           - **æé—®**ï¼šåœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥é—®é¢˜ï¼Œç‚¹å‡»"ç»§ç»­å¯¹è¯"è¿›è¡Œäº’åŠ¨ã€‚
        3. ç³»ç»Ÿä¼šè®°ä½éŸ³é¢‘å†…å®¹ï¼Œæ”¯æŒå¤šè½®é—®ç­”ã€‚
        4. ä½¿ç”¨"æ¸…é™¤å¯¹è¯å†å²"æŒ‰é’®å¼€å§‹æ–°çš„å¯¹è¯ã€‚
        """
        )

    # å¦‚æœè®¾ç½®äº†è‡ªåŠ¨åˆå§‹åŒ–ï¼Œåˆ™åœ¨å¯åŠ¨å‰åˆå§‹åŒ–åº”ç”¨
    if args.auto_init:
        init_result = initialize_app(
            args.model_dir,
            args.device,
            args.understanding_api_key,
            args.understanding_api_url,
            args.specialized_api_key,
            args.specialized_api_url,
        )
        print(f"è‡ªåŠ¨åˆå§‹åŒ–ç»“æœ: {init_result}")

    # å¯åŠ¨Gradioç•Œé¢
    demo.launch(share=args.share, server_port=args.port)


if __name__ == "__main__":
    main()
